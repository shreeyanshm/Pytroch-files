{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60f19a2",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "Autograd is a core component of PyTorch that provides automatic differentiation for tensor operations. it enables gradient computation, which is essential for training machine learning models using optimization algorithms like gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149e1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e5b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2e7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x**2 + 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8932d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd438c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a50b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cacf55b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c5ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efb49140",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=t**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75798bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1b5d9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9564, grad_fn=<SinBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb00f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27248170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.8877)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32300c9a",
   "metadata": {},
   "source": [
    "One thing to note here is if we try to get y.grad, we will not get an output, because y was not a leaf node, it was a variable being used for chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580608de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557410/486760323.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  y.grad\n"
     ]
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2381b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(6.7)\n",
    "y=torch.tensor(0.0)\n",
    "\n",
    "w=torch.tensor(1.0)\n",
    "b=torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18fe98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_pred, y):\n",
    "    epsilon=1e-8\n",
    "    y_pred=torch.clamp(y_pred, epsilon, 1.0-epsilon)\n",
    "    return -(y*torch.log(y_pred) + (1-y)*torch.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72ecdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=w*x+b\n",
    "y_pred=torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4fb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=binary_cross_entropy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "585281e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd5204e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Backpropagation\n",
    "dloss_dypred=(y-y_pred)/(y_pred*(1-y_pred))\n",
    "\n",
    "dypred_dz=y_pred*(1-y_pred)\n",
    "\n",
    "dz_dw=x\n",
    "dz_db=1\n",
    "\n",
    "dL_dw=dloss_dypred*dypred_dz*dz_dw\n",
    "dL_db=dloss_dypred*dypred_dz*dz_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d2a5e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual gradient of loss w.r.t w: -6.691762447357178\n",
      "manual gradient of loss w.r.t b: -0.998770534992218\n"
     ]
    }
   ],
   "source": [
    "print(f\"manual gradient of loss w.r.t w: {dL_dw}\")\n",
    "print(f\"manual gradient of loss w.r.t b: {dL_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ca6047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(6.7)\n",
    "y=torch.tensor(0.0)\n",
    "w=torch.tensor(1.0, requires_grad=True)\n",
    "b=torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c185f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=w*x+b\n",
    "y_pred=torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31dd8703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c3a4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=binary_cross_entropy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c11bd49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d2abcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8ed111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6918)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe759b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb0791d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([1.0,2.0,3.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8029b0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78832d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=(x**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19dd09a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc874772",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f39efe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d08676b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing the grads - if forward pass is done again, then gradients will be accumulated\n",
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9aaba184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopping the gradient tracking\n",
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b25b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c00e2275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82307f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008bbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
